{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e95d5e3a",
   "metadata": {},
   "source": [
    "# Chapter 6 - Data Sourcing via Web\n",
    "## Segment 5 - Introduction to NLP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "feea0df7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6569a1cf",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"On Wednesday, the Association for Computing Machinery, the world’s largest society of computing professionals, announced that Hinton, LeCun and Bengio had won this year’s Turing Award for their work on neural networks. The Turing Award, which was introduced in 1966, is often called the Nobel Prize of computing, and it includes a $1 million prize, which the three scientists will share.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b1376a7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to /Users/randi/nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3dc82ea6",
   "metadata": {},
   "source": [
    "## Sentence Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ff5cafd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sentence tokenzing the text: \n",
      "\n",
      "['On Wednesday, the Association for Computing Machinery, the world’s largest society of computing professionals, announced that Hinton, LeCun and Bengio had won this year’s Turing Award for their work on neural networks.', 'The Turing Award, which was introduced in 1966, is often called the Nobel Prize of computing, and it includes a $1 million prize, which the three scientists will share.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import sent_tokenize\n",
    "sent_tk = sent_tokenize(text)\n",
    "print(\"Sentence tokenzing the text: \\n\")\n",
    "print(sent_tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2cbe67",
   "metadata": {},
   "source": [
    "## Word Tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0b6ef89c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word tokenzing the text: \n",
      "\n",
      "['On', 'Wednesday', ',', 'the', 'Association', 'for', 'Computing', 'Machinery', ',', 'the', 'world', '’', 's', 'largest', 'society', 'of', 'computing', 'professionals', ',', 'announced', 'that', 'Hinton', ',', 'LeCun', 'and', 'Bengio', 'had', 'won', 'this', 'year', '’', 's', 'Turing', 'Award', 'for', 'their', 'work', 'on', 'neural', 'networks', '.', 'The', 'Turing', 'Award', ',', 'which', 'was', 'introduced', 'in', '1966', ',', 'is', 'often', 'called', 'the', 'Nobel', 'Prize', 'of', 'computing', ',', 'and', 'it', 'includes', 'a', '$', '1', 'million', 'prize', ',', 'which', 'the', 'three', 'scientists', 'will', 'share', '.']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "word_tk = word_tokenize(text)\n",
    "print(\"Word tokenzing the text: \\n\")\n",
    "print(word_tk)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9bb1474",
   "metadata": {},
   "source": [
    "## Removing Stop Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "408f2710",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /Users/randi/nltk_data...\n",
      "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "9f1b5ba6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stop words in English are: \n",
      "\n",
      "{\"hasn't\", 'other', \"you'll\", 'that', 'doesn', 'at', 'further', 'were', 't', \"won't\", \"couldn't\", 'don', 'shouldn', 'where', 'what', 'same', 'won', 'should', \"you're\", 'a', 'it', 'on', 'theirs', \"wouldn't\", 'about', 'its', 'having', 'but', 'these', 'have', 'over', 'himself', 'll', 'couldn', 'very', 'doing', \"doesn't\", 'haven', \"mightn't\", 'after', \"it's\", 'myself', 'before', \"aren't\", 'no', 'between', 'because', 'nor', 'yourselves', 'itself', 'yours', 'am', 'they', \"hadn't\", \"haven't\", 'isn', 'own', 'through', 'being', 'each', \"needn't\", \"mustn't\", 'me', 'for', 'above', 'down', \"she's\", 'now', 'you', 'we', 'who', 'few', 'is', 'just', \"should've\", 'so', 'been', 'those', 'to', 'will', 'in', 'them', \"shouldn't\", 'are', 'our', \"shan't\", 've', 'has', 'him', 'aren', 'from', 'o', 'too', 'your', 'which', 'again', 'than', 'then', 'weren', \"you've\", 'not', 'shan', 'ain', 'wasn', 'ours', 'there', 'ourselves', 'this', 'when', 'mightn', 'd', 'why', 'she', 'was', 'his', 'had', 'did', 'out', \"that'll\", 'up', 'any', 'below', 'during', 'an', 'their', 'off', 'her', 'both', 'does', 'm', \"wasn't\", 'be', 'more', 'hadn', 'hasn', 'until', 's', \"don't\", 'how', 'only', 'ma', 'and', \"you'd\", 'whom', 'while', 'of', 'under', 'can', 'with', 'mustn', 'herself', 'themselves', 'y', 'needn', 'as', 'didn', 'some', 'wouldn', \"isn't\", 'the', 'i', 'do', 'once', 'here', 'all', 'if', 'by', 'such', 'hers', \"weren't\", 'into', 'against', 'yourself', 'my', 'or', 're', 'he', 'most', \"didn't\"}\n"
     ]
    }
   ],
   "source": [
    "from nltk.corpus import stopwords\n",
    "\n",
    "sw = set(stopwords.words(\"english\"))\n",
    "\n",
    "print(\"Stop words in English are: \\n\")\n",
    "print(sw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0922742",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "41889938",
   "metadata": {},
   "source": [
    "### Stemming "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffae4fc8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "99397c0b",
   "metadata": {},
   "source": [
    "## Lemmatizing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffd271cf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
